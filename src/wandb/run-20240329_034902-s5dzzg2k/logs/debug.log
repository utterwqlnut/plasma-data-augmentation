2024-03-29 03:49:02,846 INFO    MainThread:5581 [wandb_setup.py:_flush():76] Current SDK version is 0.16.4
2024-03-29 03:49:02,846 INFO    MainThread:5581 [wandb_setup.py:_flush():76] Configure stats pid to 5581
2024-03-29 03:49:02,846 INFO    MainThread:5581 [wandb_setup.py:_flush():76] Loading settings from /Users/dhruvachayapathy/.config/wandb/settings
2024-03-29 03:49:02,846 INFO    MainThread:5581 [wandb_setup.py:_flush():76] Loading settings from /Users/dhruvachayapathy/personal/research/mit-research/plasma-data-augmentation/src/wandb/settings
2024-03-29 03:49:02,846 INFO    MainThread:5581 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'entity': 'timetodisrupt', 'project': 'testing dhruva_ttd', 'sweep_id': 'u4hj6lvx', 'root_dir': '/Users/dhruvachayapathy/personal/research/mit-research/plasma-data-augmentation/src', 'run_id': 's5dzzg2k', 'sweep_param_path': '/Users/dhruvachayapathy/personal/research/mit-research/plasma-data-augmentation/src/wandb/sweep-u4hj6lvx/config-s5dzzg2k.yaml'}
2024-03-29 03:49:02,846 INFO    MainThread:5581 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-03-29 03:49:02,846 INFO    MainThread:5581 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'src/main.py', 'program_abspath': '/Users/dhruvachayapathy/personal/research/mit-research/plasma-data-augmentation/src/main.py', 'program': '/Users/dhruvachayapathy/personal/research/mit-research/plasma-data-augmentation/src/main.py'}
2024-03-29 03:49:02,846 INFO    MainThread:5581 [wandb_init.py:_log_setup():526] Logging user logs to /Users/dhruvachayapathy/personal/research/mit-research/plasma-data-augmentation/src/wandb/run-20240329_034902-s5dzzg2k/logs/debug.log
2024-03-29 03:49:02,847 INFO    MainThread:5581 [wandb_init.py:_log_setup():527] Logging internal logs to /Users/dhruvachayapathy/personal/research/mit-research/plasma-data-augmentation/src/wandb/run-20240329_034902-s5dzzg2k/logs/debug-internal.log
2024-03-29 03:49:02,847 INFO    MainThread:5581 [wandb_init.py:init():566] calling init triggers
2024-03-29 03:49:02,847 INFO    MainThread:5581 [wandb_init.py:init():573] wandb.init called with sweep_config: {'balance': True, 'e_lr': 1e-05, 'encoder_hidden_dim': 24, 'encoder_n_layers': 2, 'post_hoc_h_size': 24, 'post_hoc_lr': 0.001, 'post_hoc_n_layers': 4, 'v_lr': 1e-05, 'viewmaker_activation': 'relu', 'viewmaker_distortion_budget': 0.11245751419468686, 'viewmaker_hidden_dim': 32, 'viewmaker_layer_type': 'lstm', 'viewmaker_loss_t': 0.007764357357040433, 'viewmaker_loss_weight': 0.37232765528400424, 'viewmaker_n_head': 2, 'viewmaker_n_layers': 4}
config: {}
2024-03-29 03:49:02,848 INFO    MainThread:5581 [wandb_init.py:init():616] starting backend
2024-03-29 03:49:02,848 INFO    MainThread:5581 [wandb_init.py:init():620] setting up manager
2024-03-29 03:49:02,856 INFO    MainThread:5581 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2024-03-29 03:49:02,860 INFO    MainThread:5581 [wandb_init.py:init():628] backend started and connected
2024-03-29 03:49:02,873 INFO    MainThread:5581 [wandb_run.py:_config_callback():1343] config_cb None None {'balance': True, 'e_lr': 1e-05, 'encoder_hidden_dim': 24, 'encoder_n_layers': 2, 'post_hoc_h_size': 24, 'post_hoc_lr': 0.001, 'post_hoc_n_layers': 4, 'v_lr': 1e-05, 'viewmaker_activation': 'relu', 'viewmaker_distortion_budget': 0.11245751419468686, 'viewmaker_hidden_dim': 32, 'viewmaker_layer_type': 'lstm', 'viewmaker_loss_t': 0.007764357357040433, 'viewmaker_loss_weight': 0.37232765528400424, 'viewmaker_n_head': 2, 'viewmaker_n_layers': 4}
2024-03-29 03:49:02,876 INFO    MainThread:5581 [wandb_init.py:init():720] updated telemetry
2024-03-29 03:49:02,910 INFO    MainThread:5581 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2024-03-29 03:49:03,211 INFO    MainThread:5581 [wandb_run.py:_on_init():2262] communicating current version
2024-03-29 03:49:03,453 INFO    MainThread:5581 [wandb_run.py:_on_init():2271] got version response upgrade_message: "wandb version 0.16.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-03-29 03:49:03,453 INFO    MainThread:5581 [wandb_init.py:init():804] starting run threads in backend
2024-03-29 03:49:07,161 INFO    MainThread:5581 [wandb_run.py:_console_start():2241] atexit reg
2024-03-29 03:49:07,161 INFO    MainThread:5581 [wandb_run.py:_redirect():2096] redirect: wrap_raw
2024-03-29 03:49:07,161 INFO    MainThread:5581 [wandb_run.py:_redirect():2161] Wrapping output streams.
2024-03-29 03:49:07,161 INFO    MainThread:5581 [wandb_run.py:_redirect():2186] Redirects installed.
2024-03-29 03:49:07,162 INFO    MainThread:5581 [wandb_init.py:init():847] run started, returning control to user process
2024-03-29 03:49:07,221 INFO    MainThread:5581 [wandb_run.py:_config_callback():1343] config_cb None None {'batch_size': 12, 't': 0.007764357357040433, 'v_loss_weight': 0.37232765528400424, 'viewmaker': 'TimeSeriesViewMaker(\n  (activation): ReLU()\n  (net): Sequential(\n    (0): LSTM(13, 32, num_layers=4, batch_first=True)\n    (1): extract_tensor()\n    (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n    (3): ReLU()\n    (4): Linear(in_features=32, out_features=12, bias=True)\n    (5): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n  )\n)', 'encoder': 'PlasmaViewEncoderLSTM(\n  (lstm): LSTM(12, 24, num_layers=2, batch_first=True)\n  (out): Sequential(\n    (0): Linear(in_features=24, out_features=12, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=12, out_features=12, bias=True)\n  )\n)', 'train_dataset': '<data.PlasmaDataset object at 0x7fa536d9ff40>', 'val_dataset': '<data.PlasmaDataset object at 0x7fa526b75a50>', 'collate_fn': 'data.viewmaker_collate_fn', 'included_machines': ['cmod', 'east', 'd3d'], 'viewmaker_batch_size': 12, 'viewmaker_num_epochs': 10, 'post_hoc_num_epochs': 10, 'post_hoc_save_metric': 'accuracy', 'post_hoc_batch_size': 12}
2024-03-29 03:56:37,817 WARNING MsgRouterThr:5581 [router.py:message_loop():77] message_loop has been closed
