2024-03-31 19:52:02,964 INFO    MainThread:89064 [wandb_setup.py:_flush():76] Current SDK version is 0.16.4
2024-03-31 19:52:02,964 INFO    MainThread:89064 [wandb_setup.py:_flush():76] Configure stats pid to 89064
2024-03-31 19:52:02,964 INFO    MainThread:89064 [wandb_setup.py:_flush():76] Loading settings from /Users/dhruvachayapathy/.config/wandb/settings
2024-03-31 19:52:02,965 INFO    MainThread:89064 [wandb_setup.py:_flush():76] Loading settings from /Users/dhruvachayapathy/personal/research/mit-research/plasma-data-augmentation/src/wandb/settings
2024-03-31 19:52:02,965 INFO    MainThread:89064 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-03-31 19:52:02,965 INFO    MainThread:89064 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-03-31 19:52:02,965 INFO    MainThread:89064 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'src/main.py', 'program_abspath': '/Users/dhruvachayapathy/personal/research/mit-research/plasma-data-augmentation/src/main.py', 'program': '/Users/dhruvachayapathy/personal/research/mit-research/plasma-data-augmentation/src/main.py'}
2024-03-31 19:52:02,965 INFO    MainThread:89064 [wandb_init.py:_log_setup():526] Logging user logs to /Users/dhruvachayapathy/personal/research/mit-research/plasma-data-augmentation/src/wandb/run-20240331_195202-xjnxhz70/logs/debug.log
2024-03-31 19:52:02,965 INFO    MainThread:89064 [wandb_init.py:_log_setup():527] Logging internal logs to /Users/dhruvachayapathy/personal/research/mit-research/plasma-data-augmentation/src/wandb/run-20240331_195202-xjnxhz70/logs/debug-internal.log
2024-03-31 19:52:02,965 INFO    MainThread:89064 [wandb_init.py:init():566] calling init triggers
2024-03-31 19:52:02,965 INFO    MainThread:89064 [wandb_init.py:init():573] wandb.init called with sweep_config: {}
config: {}
2024-03-31 19:52:02,965 INFO    MainThread:89064 [wandb_init.py:init():616] starting backend
2024-03-31 19:52:02,966 INFO    MainThread:89064 [wandb_init.py:init():620] setting up manager
2024-03-31 19:52:02,972 INFO    MainThread:89064 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2024-03-31 19:52:02,977 INFO    MainThread:89064 [wandb_init.py:init():628] backend started and connected
2024-03-31 19:52:02,993 INFO    MainThread:89064 [wandb_init.py:init():720] updated telemetry
2024-03-31 19:52:03,048 INFO    MainThread:89064 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2024-03-31 19:52:03,434 INFO    MainThread:89064 [wandb_run.py:_on_init():2262] communicating current version
2024-03-31 19:52:03,585 INFO    MainThread:89064 [wandb_run.py:_on_init():2271] got version response upgrade_message: "wandb version 0.16.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-03-31 19:52:03,585 INFO    MainThread:89064 [wandb_init.py:init():804] starting run threads in backend
2024-03-31 19:52:06,999 INFO    MainThread:89064 [wandb_run.py:_console_start():2241] atexit reg
2024-03-31 19:52:06,999 INFO    MainThread:89064 [wandb_run.py:_redirect():2096] redirect: wrap_raw
2024-03-31 19:52:06,999 INFO    MainThread:89064 [wandb_run.py:_redirect():2161] Wrapping output streams.
2024-03-31 19:52:06,999 INFO    MainThread:89064 [wandb_run.py:_redirect():2186] Redirects installed.
2024-03-31 19:52:07,000 INFO    MainThread:89064 [wandb_init.py:init():847] run started, returning control to user process
2024-03-31 19:52:07,030 INFO    MainThread:89064 [wandb_run.py:_config_callback():1343] config_cb None None {'batch_size': 12, 't': 0.0001, 'v_loss_weight': 0.5, 'v_lr': 0.001, 'e_lr': 0.001, 'viewmaker': 'TimeSeriesViewMaker(\n  (activation): ReLU()\n  (net): Sequential(\n    (0): LSTM(13, 12, num_layers=2, batch_first=True)\n    (1): extract_tensor()\n    (2): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n    (3): ReLU()\n    (4): Linear(in_features=12, out_features=12, bias=True)\n    (5): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n  )\n)', 'encoder': 'PlasmaViewEncoderLSTM(\n  (lstm): LSTM(12, 12, num_layers=2, batch_first=True)\n  (out): Sequential(\n    (0): Linear(in_features=12, out_features=12, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=12, out_features=12, bias=True)\n  )\n)', 'train_dataset': '<data.PlasmaDataset object at 0x7febf78a3f40>', 'val_dataset': '<data.PlasmaDataset object at 0x7febf255ba60>', 'collate_fn': 'data.viewmaker_collate_fn', 'included_machines': ['cmod', 'east', 'd3d'], 'balance': True, 'viewmaker_n_head': 1, 'viewmaker_n_layers': 2, 'viewmaker_activation': 'relu', 'viewmaker_distortion_budget': 0.1, 'viewmaker_hidden_dim': 12, 'viewmaker_layer_type': 'lstm', 'encoder_n_layers': 2, 'encoder_hidden_dim': 12, 'viewmaker_loss_t': 0.0001, 'viewmaker_loss_weight': 0.5, 'viewmaker_batch_size': 12, 'viewmaker_num_epochs': 10, 'post_hoc_n_layers': 2, 'post_hoc_h_size': 12, 'post_hoc_num_epochs': 10, 'post_hoc_save_metric': 'accuracy', 'post_hoc_batch_size': 12, 'post_hoc_lr': 0.001}
